{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Systems\n",
    "\n",
    "In this practical, you are asked to compare the prediction error of:\n",
    "\n",
    " 1. The Naive Bayes Classifier\n",
    " 2. LDA\n",
    " 3. QDA\n",
    " 4. Nearest Shrunken Centroids Classifier\n",
    "\n",
    "On the Breast Cancer dataset provided in the previous notebooks, and the Prostate cancer dataset attached. The details about this last dataset are found in the reference:\n",
    "\n",
    "Singh, D., Febbo, P., Ross, K., Jackson, D., Manola, J., Ladd, C., Tamayo, P., Renshaw, A., D’Amico, A., Richie, J., Lander, E., Loda, M., Kantoff, P., Golub, T., & Sellers, W. (2002). Gene expression correlates of clinical prostate cancer behavior. Cancer Cell, 1, 203–209.\n",
    "\n",
    "This dataset is in CSV format and the last column contains the class label. The task of interest is to discriminate between normal and tumor tissue samples.\n",
    "\n",
    "Importantly:\n",
    "\n",
    "Use a random split of 2 / 3 of the data for training and 1 / 3 for testing each classifier. \n",
    "Any hyper-parameter of each method should be tuned using a grid-search guided by an inner cross-validation procedure that uses only training data.\n",
    "To reduce the variance of the estimates, report average error results over 20 different partitions of the data into training and testing as described above.\n",
    "Submit a notebook showing the code and the results obtained. Give some comments about the results and respond to these questions:\n",
    "\n",
    "What method performs best on each dataset?\n",
    "What method is more flexible?\n",
    "What method is more robust to over-fitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# seaborn is a package for statistical data visualization\n",
    "import seaborn as sns; sns.set()\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malign' 'benign']\n",
      "13.598316715519944\n",
      "19.71087911250966\n",
      "[[ 61   5]\n",
      " [  7 117]]\n",
      "Predicion accuracy is: 0.936842\n",
      "True postive rate is: 0.943548\n",
      "True negative rate is: 0.924242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the data, 30 features for each record\n",
    "data = pd.read_csv('./data/wdbc.csv',header=None) #as there is no header in this case\n",
    "X = data.values[ :, 2:].astype(np.float)\n",
    "# as a supervised problem, we have an associated label (benign, malign) to each sample on X\n",
    "y = (data.values[ :, 1 ] == 'B').astype(np.int)\n",
    "target_names = np.array(['malign', 'benign'], dtype=np.dtype('U10'))\n",
    "print(target_names)\n",
    "\n",
    "# make a DataFrame with a species column for the first 5 features. Note that the last element is not included in the selection\n",
    "X5 = X[ :, 0:5].astype(np.float)\n",
    "df_cancer = pd.DataFrame(X5)\n",
    "df_cancer['target'] = target_names[y]\n",
    "\n",
    "# take a look at df_cancer. \n",
    "df_cancer.head(5)\n",
    "\n",
    "# Split dataset between training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1.0/3, random_state=1)\n",
    "\n",
    "# Data standardization\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check standardization\n",
    "print(np.var(X_train[:,0]))\n",
    "print(np.var(X_train[:,1]))\n",
    "for i in range (1, np.size(X_train_scaled,1)):\n",
    "    assert round(np.var(X_train_scaled[:,0]),3) == round(np.var(X_train_scaled[:,i]),3),\\\n",
    "    \"Warning: revise standardization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61   5]\n",
      " [  7 117]]\n",
      "Predicion accuracy is: 0.936842\n",
      "True postive rate is: 0.943548\n",
      "True negative rate is: 0.924242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "# Training\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = nb.predict(X_test_scaled)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# The matrix conf contains:\n",
    "# TN | FN\n",
    "# FP | TP\n",
    "\n",
    "TN = conf[0][0]\n",
    "TP = conf[1][1]\n",
    "FP = conf[0][1]\n",
    "FN = conf[1][0]\n",
    "\n",
    "print(conf)\n",
    "print('Predicion accuracy is: %f' % ((TP + TN) / (TN + TP + FP + FN)))\n",
    "print('True postive rate is: %f' % (TP / (TP + FN)))\n",
    "print('True negative rate is: %f\\n' % (TN / (TN + FP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "latex_metadata": {
     "hidden": "true"
    }
   },
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "latex_metadata": {
     "hidden": "true",
     "lexer": "bash"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook classification_systems.ipynb to latex\n",
      "[NbConvertApp] Writing 29868 bytes to classification_systems.tex\n",
      "[NbConvertApp] Converting notebook classification_systems.ipynb to html_with_toclenvs\n",
      "[NbConvertApp] Writing 293429 bytes to classification_systems.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "jupyter nbconvert --to=latex --template=~/report.tplx classification_systems.ipynb 1> /dev/null\n",
    "pdflatex -shell-escape classification_systems 1> /dev/null\n",
    "jupyter nbconvert --to html_with_toclenvs classification_systems.ipynb 1> /dev/null"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "latex_metadata": {
   "author": "Daniel Cerdán, Fernando Freire",
   "title": "Classification Systems"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "sp"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "sp",
   "targetLang": "en",
   "useGoogleTranslate": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
